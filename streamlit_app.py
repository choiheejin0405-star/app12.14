import streamlit as st
import google.generativeai as genai
import PyPDF2
from docx import Document
import os

# 1. API í‚¤ ì„¤ì • (ë¹„ë°€ë²ˆí˜¸)
try:
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
except:
    st.error("ì„¤ì •ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
    st.stop()

# 2. í™”ë©´ ì„¤ì •
st.set_page_config(page_title="4.ìš°ë¦¬ ëª¸ì˜ êµ¬ì¡°ì™€ ê¸°ëŠ¥", page_icon="ğŸ©º")
st.title("4.ìš°ë¦¬ ëª¸ì˜ êµ¬ì¡°ì™€ ê¸°ëŠ¥")
st.caption("ì„ ìƒë‹˜ê³¼ í•¨ê»˜ ìš°ë¦¬ ëª¸ì— ëŒ€í•´ ì¬ë¯¸ìˆê²Œ ì•Œì•„ë³´ì•„ìš”!")

# 3. ëª¨ë¸ ì—°ê²° (ì•ˆì „ì¥ì¹˜ ê°•í™”: Flash ì‹¤íŒ¨ ì‹œ Proë¡œ ìë™ ì „í™˜)
@st.cache_resource
def get_model():
    genai.configure(api_key=GOOGLE_API_KEY)
    
    # ì‹œë„í•  ëª¨ë¸ ìˆœì„œ: 1.5 Flash (ë¹ ë¦„) -> 1.5 Pro (ë˜‘ë˜‘í•¨) -> Pro (êµ¬í˜•, ì•ˆì •ì )
    candidate_models = ["gemini-1.5-flash", "gemini-1.5-pro", "gemini-pro"]
    
    selected_model = None
    model_name_log = ""

    for model_name in candidate_models:
        try:
            # ëª¨ë¸ ì—°ê²° ì‹œë„
            temp_model = genai.GenerativeModel(model_name)
            # í…ŒìŠ¤íŠ¸ ë°œì‚¬ (ì§„ì§œ ë˜ëŠ”ì§€ í™•ì¸)
            temp_model.generate_content("test")
            selected_model = temp_model
            model_name_log = model_name
            break # ì„±ê³µí•˜ë©´ ë°˜ë³µ ì¤‘ë‹¨
        except Exception:
            continue # ì‹¤íŒ¨í•˜ë©´ ë‹¤ìŒ ëª¨ë¸ë¡œ ë„˜ì–´ê°

    return selected_model, model_name_log

# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤í–‰
model, connected_name = get_model()

if model is None:
    st.error("ğŸ˜­ ëª¨ë“  AI ëª¨ë¸ ì—°ê²°ì— ì‹¤íŒ¨í–ˆì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    st.stop()
else:
    # ì‚¬ì´ë“œë°”ì— ì—°ê²°ëœ ëª¨ë¸ í‘œì‹œ
    st.sidebar.success(f"âœ… ì—°ê²° ì„±ê³µ! ({connected_name})")

# 4. ìë£Œ ì½ê¸° í•¨ìˆ˜
@st.cache_data(show_spinner=False)
def load_data():
    folder_path = 'data'
    combined_text = ""
    if not os.path.exists(folder_path): return ""
    
    files = os.listdir(folder_path)
    KEYWORDS = ["ë¼ˆ", "ê·¼ìœ¡", "ì†Œí™”", "ì‹¬ì¥", "í˜¸í¡", "ë°°ì„¤", "ë‡Œ", "ì‹ ê²½"]

    for filename in files:
        path = os.path.join(folder_path, filename)
        try:
            content = ""
            if filename.endswith('.pdf'):
                with open(path, 'rb') as f:
                    pdf = PyPDF2.PdfReader(f)
                    for page in pdf.pages: content += page.extract_text()
            elif filename.endswith('.docx'):
                doc = Document(path)
                for para in doc.paragraphs: content += para.text + "\n"
            elif filename.endswith('.txt'):
                with open(path, 'r', encoding='utf-8') as f: content = f.read()
            
            if any(k in content for k in KEYWORDS):
                combined_text += f"\n[ìë£Œ: {filename}]\n{content}"
        except: pass
    return combined_text[:50000]

# 5. ì±—ë´‡ ë³¸ì²´
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•! ìš°ë¦¬ ëª¸ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²Œ ìˆë‹ˆ? ì„ ìƒë‹˜ì´ ì•Œë ¤ì¤„ê²Œ! ğŸ˜Š"}]

# ìë£Œ ë¡œë”©
if "knowledge" not in st.session_state:
    st.session_state.knowledge = load_data()

# í™”ë©´ì— ëŒ€í™” ê·¸ë¦¬ê¸°
for msg in st.session_state.messages:
    icon = "ğŸ§‘â€ğŸ«" if msg["role"] == "assistant" else "ğŸ§‘â€ğŸ“"
    st.chat_message(msg["role"], avatar=icon).write(msg["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì§ˆë¬¸ ì…ë ¥..."):
    st.chat_message("user", avatar="ğŸ§‘â€ğŸ“").write(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # ë‹µë³€ ìƒì„±
    with st.chat_message("assistant", avatar="ğŸ§‘â€ğŸ«"):
        box = st.empty()
        try:
            sys_prompt = f"""
            ë‹¹ì‹ ì€ ì´ˆë“±í•™êµ 6í•™ë…„ ê³¼í•™ ì„ ìƒë‹˜ì…ë‹ˆë‹¤.
            ì§€ì‹: {st.session_state.knowledge}
            
            [ê·œì¹™]
            1. ì´ˆë“±í•™ìƒ ëˆˆë†’ì´ë¡œ ì‰½ê³  ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
            2. ìš•ì„¤, í­ë ¥, ìœ„í—˜í•œ ì§ˆë¬¸ì€ ë‹¨í˜¸í•˜ê²Œ ê±°ì ˆí•˜ê³  ì˜¬ë°”ë¥¸ íƒœë„ë¥¼ ì§€ë„í•˜ì„¸ìš”.
            3. í‹€ë¦° ë‚´ìš©ì„ ë§í•˜ë©´ ì •ë‹µì„ ë°”ë¡œ ì£¼ì§€ ë§ê³ , íŒíŠ¸ë¥¼ ì£¼ì–´ ìŠ¤ìŠ¤ë¡œ ìƒê°í•˜ê²Œ í•˜ì„¸ìš”.
            """
            
            full_prompt = sys_prompt + "\ní•™ìƒ: " + prompt
            response = model.generate_content(full_prompt, stream=True)
            
            full_text = ""
            for chunk in response:
                full_text += chunk.text
                box.markdown(full_text + "â–Œ")
            box.markdown(full_text)
            st.session_state.messages.append({"role": "assistant", "content": full_text})
        except Exception as e:
            box.error(f"ì˜¤ë¥˜ê°€ ë‚¬ì–´ìš”: {e}")